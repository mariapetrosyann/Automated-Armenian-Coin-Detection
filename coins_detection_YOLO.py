# -*- coding: utf-8 -*-
"""Coins_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12ckzd6ZJ-aH6f6Eyz984qlEba1jqK-Ll
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
import os
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# Define the path to your dataset
source_path = '/content/drive/MyDrive/PS5/Armenian_Coins/data'
destination_path = '/content/dataset'

# Define the class mapping (adjust as needed)
class_mapping = {
    "10dram": 0,
    "20dram": 1,
    "50dram": 2,
    "100dram": 3,
    "200dram": 4,
    "500dram": 5
}

# Create destination folders
os.makedirs(f"{destination_path}/images/train", exist_ok=True)
os.makedirs(f"{destination_path}/images/val", exist_ok=True)
os.makedirs(f"{destination_path}/labels/train", exist_ok=True)
os.makedirs(f"{destination_path}/labels/val", exist_ok=True)

import cv2
import random

# Collect all images and their corresponding class
all_data = []
for class_name, class_id in class_mapping.items():
    class_folder = os.path.join(source_path, class_name)
    for image_file in os.listdir(class_folder):
        if image_file.endswith(('.jpg', '.png', '.jpeg')):
            all_data.append((os.path.join(class_folder, image_file), class_id))

# Split the data into training and validation sets
train_data, val_data = train_test_split(all_data, test_size=0.2, random_state=42)

def create_yolo_annotation(image_path, class_id, output_dir):
    """Generate YOLO annotation for a full-image bounding box."""
    # Read the image to get dimensions
    image = cv2.imread(image_path)
    h, w, _ = image.shape

    # YOLO bounding box (entire image)
    x_center, y_center = 0.5, 0.5
    bbox_width, bbox_height = 1.0, 1.0

    # Create annotation line
    annotation = f"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\n"

    # Save annotation to file
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    annotation_path = os.path.join(output_dir, f"{base_name}.txt")
    with open(annotation_path, "w") as f:
        f.write(annotation)

# Process training data
for image_path, class_id in tqdm(train_data, desc="Processing Training Data"):
    # Copy image
    dest_image = f"{destination_path}/images/train/{os.path.basename(image_path)}"
    os.system(f"cp '{image_path}' '{dest_image}'")

    # Generate annotation
    create_yolo_annotation(image_path, class_id, f"{destination_path}/labels/train")

# Process validation data
for image_path, class_id in tqdm(val_data, desc="Processing Validation Data"):
    # Copy image
    dest_image = f"{destination_path}/images/val/{os.path.basename(image_path)}"
    os.system(f"cp '{image_path}' '{dest_image}'")

    # Generate annotation
    create_yolo_annotation(image_path, class_id, f"{destination_path}/labels/val")

data_yaml = f"""
train: {destination_path}/images/train
val: {destination_path}/images/val

nc: {len(class_mapping)}  # Number of classes
names: {list(class_mapping.keys())}  # Class names
"""

# Save the YAML file
with open('/content/coin_data.yaml', 'w') as f:
    f.write(data_yaml)

from ultralytics import YOLO

!pip install ultralytics

model = YOLO('yolov8n.pt')

model.train(data='/content/coin_data.yaml', epochs=50, imgsz=640)

!cp runs/detect/train/weights/best.pt /content/drive/MyDrive/PS5/coin_detector_best.pt

# Load the trained model
model = YOLO('/content/drive/MyDrive/PS5/coin_detector_best.pt')

results = model.predict(source='/content/drive/MyDrive/PS5/coins.jpg', imgsz=640, conf=0.5)

# Define the mapping for denominations
denomination_mapping = {
    0: 10,  # Class 0 corresponds to 10 dram
    1: 20,  # Class 1 corresponds to 20 dram
    2: 50,  # Class 2 corresponds to 50 dram
    3: 100, # Class 3 corresponds to 100 dram
    4: 200, # Class 4 corresponds to 200 dram
    5: 500  # Class 5 corresponds to 500 dram
}

# Calculate total value
total_sum = 0
for box in results[0].boxes:
    class_id = int(box.cls.cpu().numpy())
    total_sum += denomination_mapping.get(class_id, 0)

print(f"Total detected sum: {total_sum} dram")

# Visualize the result
results[0].plot()

# Perform inference
results = model.predict(source='/content/drive/MyDrive/PS5/coins.jpg', imgsz=640, conf=0.5)

# Save the output image in Google Drive
output_path = '/content/drive/MyDrive/PS5/coins_detected.jpg'
results[0].save_dir = output_path  # Save the plotted image to a custom path
print(f"Output image saved at: {output_path}")

# Debug: Raw prediction outputs
print("Debugging Predictions:")
for result in results[0].boxes:
    class_id = int(result.cls.item())  # Convert tensor to int
    confidence = result.conf.item()    # Convert tensor to float
    print(f"Class: {class_id}, Confidence: {confidence:.2f}, Coordinates: {result.xyxy.tolist()}")

# Count coins from predictions
for result in results[0].boxes:
    class_id = int(result.cls.item())  # Convert tensor to int
    confidence = result.conf.item()    # Convert tensor to float
    if confidence > 0.05:  # Apply lower confidence threshold
        coin_value = coin_values.get(class_id, 0)
        print(f"Detected coin: {coin_value} dram with confidence {confidence:.2f}")
        detected_coins.append(coin_value)
        total_sum += coin_value

# Final total
print(f"Total sum of detected coins: {total_sum} dram")

import cv2
import os
from google.colab.patches import cv2_imshow
from IPython.display import display, HTML


# Path to the saved image
image_path = '/content/drive/MyDrive/PS5/coins6_detected_with_sum.jpg'

# Check if the file exists
if os.path.exists(image_path):
    # Read the image using OpenCV
    image = cv2.imread(image_path)

    # Convert image from BGR (OpenCV format) to RGB (Matplotlib format)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    image_rgb2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)
    # Display the title with the dynamic sum and the image
    display(HTML(f'<h1 style="text-align:left; font-size:30px;">Total sum of detected coins: {total_sum} dram</h1>'))

    # Show the image using OpenCV in Colab
    cv2_imshow(image_resized)

else:
    print(f"Error: The file at {image_path} does not exist. Please check the path.")